[comment encoding = UTF-8 /]
[**
 * Module generateNeuralNetworkKeras.
 */]
[module generateNeuralNetworkKeras('http://www.example.org/neuralnetwork')]


[**
 * Template generateNeuralNetworkKeras.
 * @param aModel
 */]
[template public generateNeuralNetworkKeras(aModel : Model)]
[comment @main/]
[file (aModel.name+'.py', false, 'UTF-8')]
from tensorflow import keras

[for (layer : Layer | aModel.orderOfLayers())]
	[if (layer.oclIsKindOf(Input))]
		[let inputLayer : Input = layer]
[generateInput(inputLayer)/]
		[/let]
	[elseif (layer.oclIsKindOf(Dense))]
		[let denseLayer : Dense = layer]
[generateDense(denseLayer)/]
		[/let]
	[elseif (layer.oclIsKindOf(Embedding))]
		[let embedding : Embedding = layer]
[generateEmbedding(embedding)/]
		[/let]
	[elseif (layer.oclIsKindOf(Bidirectional))]
		[let bidirectional : Bidirectional = layer]
[generateBidirectional(bidirectional)/]
		[/let]
	[elseif (layer.oclIsKindOf(GRU))]
		[let gru : GRU = layer]
[generateGru(gru)/]
		[/let]
	[elseif (layer.oclIsKindOf(Dropout))]
		[let dropout : Dropout = layer]
[generateDropout(dropout)/]
		[/let]
	[elseif (layer.oclIsKindOf(Concatenate))]
		[let concatenate : Concatenate = layer]
[generateConcatenate(concatenate)/]
		[/let]
	[elseif (layer.oclIsKindOf(CustomLayer))]
		[let customLayer : CustomLayer = layer]
[generateCustomLayer(customLayer)/]
		[/let]
	[/if]
[/for]
[aModel.name/] = keras.Model(['['/][for (inputLayer : Layer | aModel.inputLayers)][inputLayer.name/],[/for][']'/], ['['/][for (outputLayer : Layer | aModel.outputLayers)][outputLayer.name/],[/for][']'/])
[aModel.name/].compile(optimizer="[aModel.optimizer.toString().toLower()/]", loss="[aModel.loss.toString().toLower()/]")
[/file]

[/template]

[template private generateInput(inputLayer : Input)]
[inputLayer.name/] = keras.Input(shape=[inputLayer.shape/][if(inputLayer.dtype <> null)], name="[inputLayer.name/]", dtype="[inputLayer.dtype/]"[/if], sparse=[inputLayer.sparse.toString().toUpperFirst()/])[if(inputLayer.previousLayers->size()>0)](['['/][for (layer : Layer | inputLayer.previousLayers)][layer.name/],[/for][']'/])[/if]
[/template]

[template private generateDense(denseLayer : Dense)]
[denseLayer.name/] = keras.layers.Dense(units=[denseLayer.units/], activation="[denseLayer.activationFunction.toString().toLower()/]", use_bias=[denseLayer.useBias.toString().toUpperFirst()/], kernel_initializer="[denseLayer.kernelInitializer.toString().toLower()/]", bias_initializer="[denseLayer.biasInitializer.toString().toLower()/]")[if(denseLayer.previousLayers->size()>0)]([for (layer : Layer | denseLayer.previousLayers)][layer.name/][/for])[/if]
[/template]

[template private generateEmbedding(embedding : Embedding)]
[embedding.name/] = keras.layers.Embedding([embedding.inputDim/], [embedding.outputDim/], embeddings_initializer="[embedding.embeddingsInitializer.toString().toLower()/]", mask_zero=[embedding.maskZero.toString().toUpperFirst()/])[if(embedding.previousLayers->size()>0)]([if (embedding.previousLayers->size()>0)][for (layer : Layer | embedding.previousLayers)][layer.name/][/for])[/if][/if]
[/template]

[template private generateBidirectional(bidirectional : Bidirectional)]
		[let inLayer : Layer = bidirectional.layer]
[bidirectional.name/] = keras.layers.Bidirectional([bidirectional.layer.name/], merge_mode="[bidirectional.mergeMode.toString().toLower()/]")[if(bidirectional.previousLayers->size()>0)](['['/][for (layer : Layer | bidirectional.previousLayers)][if(layer <> inLayer)][layer.name/],[/if][/for][']'/])[/if]
		[/let]
[/template]

[template private generateGru(gru : GRU)]
[gru.name/] = keras.layers.GRU([gru.units/], activation="[gru.activationFunction.toString().toLower()/]", recurrent_activation="[gru.recurrentActivation.toString().toLower()/]", use_bias=[gru.useBias.toString().toUpperFirst()/], kernel_initializer="[gru.kernelInitializer.toString().toLower()/]", recurrent_initializer="[gru.recurrentInitializer.toString().toLower()/]", bias_initializer="[gru.biasInitializer.toString().toLower()/]", return_sequences=[gru.returnSequences.toString().toUpperFirst()/])[if((gru.previousLayers->size()>0)) or (not gru.initialState -> isEmpty())]([if(gru.previousLayers->size()>0)][for (layer : Layer | gru.previousLayers)][if (layer <> gru.initialState)][layer.name/][/if][/for][/if][if (not gru.initialState -> isEmpty() )], initial_state=[gru.initialState.name/][/if])[/if]
[/template]

[template private generateDropout(dropout : Dropout)]
[dropout.name/] = keras.layers.Dropout([dropout.rate/])[if(dropout.previousLayers->size()>0)](['['/][for (layer : Layer | dropout.previousLayers)][layer.name/],[/for][']'/])[/if]
[/template]

[template private generateConcatenate(concatenate : Concatenate)]
[concatenate.name/] = keras.layers.Concatenate(axis=[concatenate.axis.toString()/])[if(concatenate.previousLayers->size()>0)](['['/][for (layer : Layer | concatenate.previousLayers)][layer.name/],[/for][']'/])[/if]
[/template]

[template private generateCustomLayer(customLayer : CustomLayer)]
[file (customLayer.className+'.py', false, 'UTF-8' )]
from tensorflow import keras

class [customLayer.className/](keras.layers.Layer):
	def __init__(self,[for  (arg : String | customLayer.getInitArgumentsParsed())] [arg.toString()/],[/for] **kwargs):
		super().__init__(**kwargs)
		# TODO: Check preinitiliazed arguments
		[for  (arg : String | customLayer.getInitArgumentsParsed())]
		self.[arg.toString()/] = [arg.toString()/]
		[/for]
	
	def call(self, inputs):
		# [protected ('call')]
		# TODO: Define call method
		# [/protected]

	def get_config(self):
		config = super().get_config()
		config.update(
			{
			[for (arg : String | customLayer.getInitArgumentsParsed())]
				"[arg/]": self.[arg/],
			[/for]
			}
		)
		return config
[/file]
from [customLayer.className/] import [customLayer.className/]
[customLayer.name/] = [customLayer.className/]("TODO: Define inputs")[if(customLayer.previousLayers->size()>0)](['['/][for (layer : Layer | customLayer.previousLayers)][layer.name/],[/for][']'/])[/if]
[/template]